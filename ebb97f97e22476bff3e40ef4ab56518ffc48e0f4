{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "80b2acd0_b0fe4108",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1000464
      },
      "writtenOn": "2021-08-13T07:04:28Z",
      "side": 1,
      "message": "Please review.",
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9c9ab388_ff39704d",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000114
      },
      "writtenOn": "2021-08-20T01:06:01Z",
      "side": 1,
      "message": "sorry, where is the deadlock? the deadlock cannot happen because the loop acquires and releases the lock always....\ncore 1 changes state and executes mm, when it wants to release it, it will be able to acquire the lock when the second core releases it since it is not indefinitely holding the lock..",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8b00e57d_b4e6d2d8",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000464
      },
      "writtenOn": "2021-08-21T07:50:19Z",
      "side": 1,
      "message": "In my test, core 1 can\u0027t acquire the lock. After modify with this patch, it works.\nMay be some wrong with the lib/locks/exclusive/aarch64/spinlock.S ?\nHas anyone done an experiment like me? The first core enter MM and the second core wait to enter MM.",
      "parentUuid": "9c9ab388_ff39704d",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "51d94a79_70f48435",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000114
      },
      "writtenOn": "2021-08-21T15:06:36Z",
      "side": 1,
      "message": "this has been used in the wild for a while so i\u0027m sure this has been tested. one possible approach to figure out if it is an issue is to use tftf to stress this code on fvp and then some real hardware..\nspinlock.S has been around a while and is widely used so would think something is wrong only after exhausting other possibilities.\n\nsecond core is SUPPOSED to wait for first core to finish by design. Standalone MM partition is not re-entrant or multi-threaded which is why the spinlock and state machine exists.. are you expecting to enter MM on multiple cores?",
      "parentUuid": "8b00e57d_b4e6d2d8",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9055fc87_287c0508",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000464
      },
      "writtenOn": "2021-08-22T03:59:50Z",
      "side": 1,
      "message": "I just expect one core enter MM, another core should wait the first core finish and then enter MM, not enter MM simultaneously.\n\nI use on haps not real hardware. My test:\nRegister one spi interrupt in TF-A for error inject(einj). While the spi interrupt tigger, enter MM and inject one RAS error in MM. Another core enter TF-A because RAS interrupt and wait to enter MM. Found the first core can\u0027t acquire the lock to exit MM and the second core wait for ever.",
      "parentUuid": "51d94a79_70f48435",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4d12c265_3cb06626",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000114
      },
      "writtenOn": "2021-08-22T04:42:43Z",
      "side": 1,
      "message": "i dont see how that can happen in code. Are you seeing your second core stuck in the loop within the spin_lock function? is it possible that the MM on the first core never returned or hung since it crashed due to which the second core is unable to make progress?",
      "parentUuid": "9055fc87_287c0508",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1a34a102_8c5e29bf",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000464
      },
      "writtenOn": "2021-08-22T14:39:58Z",
      "side": 1,
      "message": "I add debug log in sp_state_set() and sp_state_wait_switch().\nThe second core stuck in the loop but not within the spin_lock always. The first core go to sp_state_set(), but can\u0027t acquire the spin_lock.\n\nDebug code:\nvoid sp_state_set(sp_context_t *sp_ptr, sp_state_t state)\n{\n\tINFO(\"--exitmm:\\n\");\n\tspin_lock(\u0026(sp_ptr-\u003estate_lock));\n\tINFO(\"--get lock:\\n\");\n\tsp_ptr-\u003estate \u003d state;\n\tspin_unlock(\u0026(sp_ptr-\u003estate_lock));\n\tINFO(\"--unlock:\\n\");\n}\n\nvoid sp_state_wait_switch(sp_context_t *sp_ptr, sp_state_t from, sp_state_t to)\n{\n\tint success \u003d 0;\n\tint i \u003d 0;\n\n\twhile (success \u003d\u003d 0) {\n\t\tspin_lock(\u0026(sp_ptr-\u003estate_lock));\n\t\tif ((i % 10000) \u003d\u003d 0) INFO(\"--wait:%d\\n\", i);\n\t\ti++;\n\t\tinv_dcache_range ((uint64_t)\u0026sp_ptr-\u003estate, 8);\n\t\tif (sp_ptr-\u003estate \u003d\u003d from) {\n\t\t\tsp_ptr-\u003estate \u003d to;\n\t\t\tclean_dcache_range ((uint64_t)\u0026sp_ptr-\u003estate, 8);\n\n\t\t\tsuccess \u003d 1;\n\t\t}\n\t\tspin_unlock(\u0026(sp_ptr-\u003estate_lock));\n\t}\n}\n-----------------\nDebug log:\n[root@m1rootfs einj]$echo 1 \u003e error_inject\nINFO:    Core[0](0x81000000) received ras intr\u003d115, cnt\u003d3.\nINFO:    --wait:0\nEinj ErrType:100 Flags:1, ApicId:0\nInject PCIe error S:0 B:0 D:2 F:0\nRpEcam:50010000 DevEcam:50200000 VsecOffset:334\nINFO:    Core[1](0x81010000) received ras intr\u003d415, cnt\u003d1.\nINFO:    --wait:0\nINFO:    --exitmm:\nINFO:    --wait:10000\nINFO:    --wait:20000\nINFO:    --wait:30000\nINFO:    --wait:40000\nINFO:    --wait:50000\nINFO:    --wait:60000\n...",
      "parentUuid": "4d12c265_3cb06626",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f05632bc_8a802321",
        "filename": "services/std_svc/spm_mm/spm_mm_main.c",
        "patchSetId": 1
      },
      "lineNbr": 53,
      "author": {
        "id": 1000114
      },
      "writtenOn": "2021-08-23T02:40:17Z",
      "side": 1,
      "message": "i see statements that invalidate and clean dcache range that isnt in the original code. if that fixes the issue, it probably means memory is not marked appropriately and you are having coherency issues. is the sp_context_t structure in normal cacheable and coherent memory?\ni\u0027ve seen issues where some SRAM\u0027s where BL31 runs from, does not necessarily support exclusive monitors and cannot use load exclusive and store exclusive instructions.",
      "parentUuid": "1a34a102_8c5e29bf",
      "range": {
        "startLine": 51,
        "startChar": 2,
        "endLine": 53,
        "endChar": 19
      },
      "revId": "ebb97f97e22476bff3e40ef4ab56518ffc48e0f4",
      "serverId": "8f6f209b-db1a-4cbf-aa44-c8bc30e9bfda"
    }
  ]
}